# ğŸ§  BrainBot - CAG (Creation Augmented Generation)

An intelligent Telegram bot that acts as your personal filing assistant. Send it any information and it automatically organizes everything without asking questions - like having a hyper-competent assistant who just handles knowledge management.

> **Architecture**: Webhook-based (production) | Polling (local development)  
> **Philosophy**: Append-only, source-preserving, auto-organizing

## ğŸ¯ Core Features

- **Auto-Organization**: Intelligently files information without user intervention
- **Source Preservation**: Every input preserved with audit trail
- **Smart Merging**: Automatically combines similar content while keeping sources
- **Natural Search**: Ask questions in plain language, get relevant answers
- **No Questions Asked**: The bot decides how to organize, not you
- **Cross-Device Sync**: Dump notes from any device, access from anywhere

## ğŸš€ How It Works

1. **Send any text** to the bot via Telegram
2. **Bot analyzes** content and existing knowledge structure  
3. **Auto-files** by either merging with similar content or creating new
4. **Preserves sources** - every derivative references its origins
5. **Brief confirmation** - "Added to project notes" or "Merged with existing FAQ"

Think of it as "Git for thoughts" - all versions preserved, intelligently organized.

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.9+
- Telegram Bot Token (from [@BotFather](https://t.me/botfather))
- OpenAI API Key
- Upstash Redis database (for conversation persistence)
- Upstash Vector database (for semantic search)

### 2. Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd markdown-brain-bot

# Install dependencies
pip install -r requirements.txt

# Copy .env template and add your keys
cp .env.example .env
# Edit .env with your TELEGRAM_BOT_TOKEN and OPENAI_API_KEY
```

### 3. Running Locally

```bash
# FOR LOCAL DEVELOPMENT - Use polling mode (no webhook needed)
python run_bot.py

# Alternative: run polling directly
python src/bot/main_polling.py
```

### 4. Production Deployment (Webhook Mode)

```bash
# Production uses webhooks - DO NOT use polling in production!
# Render automatically runs: python webhook_server.py
# This starts a FastAPI server that receives webhook events

# To set up webhook after deployment:
python setup_webhook.py  # or python src/bot/set_webhook.py
```

## ğŸ“ Usage Examples

### Creating Content
- "Create a shopping list with milk, eggs, and bread"
- "Make a note about the team meeting tomorrow"
- "Create a recipe for chocolate chip cookies"

### Adding to Existing Content
- "Add butter to the shopping list"
- "Add a note about the deadline to the team meeting"

### Reading Content
- "What's on the shopping list?"
- "Show me the team meeting notes"
- "What's in the cookie recipe?"

### Searching
- "Find all notes about meetings"
- "Search for recipes"
- "What notes do we have?"

## ğŸ“‚ Project Structure

```
markdown-brain-bot/
â”œâ”€â”€ ğŸ­ PRODUCTION FILES
â”œâ”€â”€ webhook_server.py           # â­ PRODUCTION: FastAPI webhook server
â”œâ”€â”€ setup_webhook.py            # â­ PRODUCTION: Configure webhook URL
â”œâ”€â”€ requirements.txt            # â­ PRODUCTION: Dependencies
â”œâ”€â”€ render.yaml                 # â­ PRODUCTION: Render deployment config
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ .gitignore                  # Git ignore file
â”‚
â”œâ”€â”€ ğŸ§ª LOCAL TESTING FILES
â”œâ”€â”€ run_bot.py                  # ğŸ§ª LOCAL: Run bot with polling
â”œâ”€â”€ test_bot_local.py          # ğŸ§ª LOCAL: Duplicate of run_bot.py (DELETE THIS)
â”œâ”€â”€ main.py                     # âš ï¸ CONFUSING: Production file that uses polling
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bot/                    # Bot-specific code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main_polling.py    # ğŸ§ª LOCAL: Polling implementation
â”‚   â”‚   â”œâ”€â”€ main_webhook.py    # â­ PRODUCTION: Webhook implementation
â”‚   â”‚   â””â”€â”€ set_webhook.py     # â­ PRODUCTION: Alternative webhook setter
â”‚   â”œâ”€â”€ storage/                # Storage services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ storage_service.py
â”‚   â”‚   â”œâ”€â”€ media_storage.py
â”‚   â”‚   â”œâ”€â”€ redis_store.py
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”œâ”€â”€ core/                   # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ tools.py
â”‚   â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â”œâ”€â”€ chunking.py
â”‚   â”‚   â””â”€â”€ version.py
â”‚   â””â”€â”€ migrations/             # Data migration scripts
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ migrate_to_vector.py
â”‚       â””â”€â”€ add_to_vector.py
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ diagnostics/           # Diagnostic tools
â”‚   â”‚   â”œâ”€â”€ diagnose_vector.py
â”‚   â”‚   â”œâ”€â”€ remote_diagnostic.py
â”‚   â”‚   â””â”€â”€ list_vector_contents.py
â”‚   â”œâ”€â”€ deployment/            # Deployment scripts
â”‚   â”‚   â”œâ”€â”€ bot-restart.sh
â”‚   â”‚   â”œâ”€â”€ botlogs.sh
â”‚   â”‚   â””â”€â”€ start.py
â”‚   â””â”€â”€ database/              # Database scripts
â”‚       â”œâ”€â”€ create_document_storage_tables.sql
â”‚       â””â”€â”€ audit_queries.sql
â”‚
â”œâ”€â”€ tests/                     # All tests
â”‚   â”œâ”€â”€ integration/           # Integration tests
â”‚   â”‚   â”œâ”€â”€ test_document_storage.py
â”‚   â”‚   â”œâ”€â”€ test_media_storage.py
â”‚   â”‚   â””â”€â”€ test_s3_connection.py
â”‚   â”œâ”€â”€ unit/                  # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_context_awareness.py
â”‚   â”‚   â””â”€â”€ test_search_resilience.py
â”‚   â””â”€â”€ scratch/               # Temporary test files
â”‚       â”œâ”€â”€ test_chunked_migration.py
â”‚       â”œâ”€â”€ test_chunking.py
â”‚       â””â”€â”€ test_full_content_search.py
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md
â”‚   â”œâ”€â”€ STORAGE_IMPLEMENTATION_PLAN.md
â”‚   â”œâ”€â”€ STORAGE_OPTIONS.md
â”‚   â””â”€â”€ VECTOR_ENHANCEMENT_PLAN.md
â”‚
â”œâ”€â”€ notes/                     # Knowledge base (unchanged)
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ logs/                      # Log files (unchanged)
    â””â”€â”€ ...
```

## ğŸ”§ Configuration

Environment variables in `.env`:

```env
# Required
TELEGRAM_BOT_TOKEN=your_bot_token_here
OPENAI_API_KEY=your_openai_api_key_here
UPSTASH_REDIS_REST_URL=your_upstash_redis_url_here
UPSTASH_REDIS_REST_TOKEN=your_upstash_redis_token_here
UPSTASH_VECTOR_REST_URL=your_upstash_vector_url_here
UPSTASH_VECTOR_REST_TOKEN=your_upstash_vector_token_here

# Optional
VECTOR_NAMESPACE=10netzero
VECTOR_TOP_K=5

# Performance Configuration (NEW)
VECTOR_CACHE_ENABLED=true          # Enable vector search caching
VECTOR_CACHE_TTL=300              # Cache TTL in seconds (5 minutes)
CONVERSATION_MAX_MESSAGES=20       # Max messages in conversation window
CONVERSATION_TTL_HOURS=24         # Hours before conversation expires
```

## ğŸš¢ Deployment

### Render.com (Recommended)

1. **Set up Upstash services**:
   - Create [Upstash Redis](https://upstash.com) database
   - Create [Upstash Vector](https://upstash.com/docs/vector) database
   - Note the REST URLs and tokens

2. **Deploy to Render**:
   - Fork this repository to your GitHub account
   - Connect your forked repository to Render
   - Use the included `render.yaml` configuration
   - Set environment variables in Render dashboard:
     - `TELEGRAM_BOT_TOKEN` (from @BotFather)
     - `OPENAI_API_KEY` (from OpenAI)
     - `UPSTASH_REDIS_REST_URL` & `UPSTASH_REDIS_REST_TOKEN`
     - `UPSTASH_VECTOR_REST_URL` & `UPSTASH_VECTOR_REST_TOKEN`

3. **Initialize knowledge base** (optional):
   - Run the migration script to populate vector database
   - Upload documents via Telegram

## ğŸ› ï¸ Development

### Running Tests

```bash
# Run all tests
python tests/test_all_storage.py

# Run performance tests specifically
python tests/test_performance.py

# Run integration tests
python tests/integration/test_storage_integrations.py
```

### Performance Monitoring

```bash
# Check real-time metrics (when bot is running)
curl http://localhost:8000/metrics

# View performance in local development
python scripts/local_dev.py
# Watch console for timing logs: â±ï¸ vector_search: 0.234s

# Run performance test suite
python tests/test_performance.py
```

See [Testing Guide](tests/README.md) and [Monitoring Guide](docs/MONITORING_GUIDE.md) for detailed information.

### File Format

All files use YAML frontmatter:

```markdown
---
title: Shopping List
type: list
created: 2025-01-18
updated: 2025-01-18 14:30:00
tags: [shopping, groceries]
---

# Shopping List

- Milk
- Eggs
- Bread
```

## ğŸš„ Smart Rails Enhancement

Smart Rails is an intelligent message routing system that combines deterministic preprocessing with dynamic prompt generation for optimal performance. It achieves **70% token reduction** and **60% faster response times** through confidence-based execution strategies.

### Key Performance Metrics

| Message Type | Traditional | Smart Rails | Token Savings |
|-------------|------------|-------------|---------------|
| `/command` syntax | 200-300 tokens | 0 tokens | 100% |
| `@mention` assignment | 150-200 tokens | 50 tokens | 75% |
| Natural language | 300-400 tokens | 150-200 tokens | 50% |

### How It Works

1. **Deterministic Preprocessing** (Phase 2.1.1)
   - Extracts `@mentions` and `/commands` with 100% confidence
   - Removes extracted syntax for clean LLM input
   - Identifies patterns (time refs, sites, etc.) before LLM

2. **Confidence-Based Routing**
   - **100% Confidence** â†’ Direct execution (0 tokens, <50ms)
   - **80-99% Confidence** â†’ Focused LLM (50-100 tokens)
   - **<80% Confidence** â†’ Full LLM analysis (200-500 tokens)

3. **Dynamic Prompt Generation** (Phase 2.1.2)
   - Context-aware prompts based on extracted data
   - Only asks for missing information
   - Caches prompts for reuse

### Command Syntax (100% Confidence)

#### Task Commands
- `/newtask` or `/newreminder` - Create task/reminder
- `/completetask` - Mark task complete
- `/reassigntask` - Reassign to another user
- `/showtasks` or `/showmytasks` - List tasks

#### List Commands
- `/newlist` - Create new list
- `/addtolist` - Add items to list
- `/removefromlist` - Remove items from list
- `/showlist` - Display list contents

#### User Assignment
- `@username` - Assigns to specific user (100% confidence)
- Multiple mentions supported: `@joel and @bryan`

### Example: Maximum Efficiency

```
/newtask for @joel: Check Eagle Lake generator tomorrow at 3pm
```

This achieves:
- **0 tokens** used (direct execution)
- **<50ms** response time
- **100% accuracy** on all extractions
- Entity, operation, assignee, site, and time all extracted

### Natural Language Support

Smart Rails still supports natural language with intelligent confidence scoring:

```
"add milk and eggs to the shopping list" â†’ 85% confidence â†’ Focused LLM (75 tokens)
"maybe update that thing we discussed" â†’ 40% confidence â†’ Full LLM (350 tokens)
```

For detailed documentation, see:
- [Architecture Guide](docs/smart-rails-architecture.md)
- [API Reference](docs/smart-rails-api.md)
- [Developer Guide](docs/smart-rails-developer-guide.md)

## ğŸ”® Roadmap

**Current (MVP)**:
- âœ… Basic auto-organization
- ğŸ”„ Source tracking for audit trails
- ğŸ”„ Supabase + Vector sync

**Next Phase**:
- [ ] Auth via Telegram + Supabase (audit trail for all interactions)
- [ ] FLRTS structure (Field reports, Lists, Reminders, Tasks, Sub-tasks)
- [ ] Chunking pipeline for all uploaded documents
- [ ] Web UI for viewing vectors/documents
- [ ] Private namespace support for multi-user isolation
- [ ] Time awareness (date injection, reminders, timers)

**Advanced Features**:
- [ ] Agent selection in Telegram bot
- [ ] Rich outputs (charts, graphs, images)
- [ ] Web search and external tools integration
- [ ] Full training mode (beyond just vector returns)
- [ ] Conversation vectorization for better memory
- [ ] Smart CAG/RAG prompt switching
- [ ] Tool calls tied to UI buttons (new task, reminder)
- [ ] Redis configuration optimization

**Infrastructure**:
- [ ] Persist all conversations to vector store
- [ ] Sync between human-readable notes and vector store
- [ ] Store all original submissions with audit trail
- [ ] Add vector-supabase sync verification to test suite

## ğŸ“„ License

MIT License - feel free to use this for your team!

## ğŸ¤ Contributing

Pull requests are welcome! Please ensure:
- Code follows Python best practices
- All functions have docstrings
- Tests pass before submitting PR

---

Built with â¤ï¸ for teams who love markdown